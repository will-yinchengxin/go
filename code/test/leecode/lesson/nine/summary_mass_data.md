### 海量数据处理
面对得两个问题:
- 一台机器的内存存不下
- 一台机器处理起来太慢

海量数据处理的核心(分治):
- 单机: 利用外存,分批加入内存处理
- 多机: 对数据分片, 利用多机内存存储
- 多机: 并行计算,利用多线程,多机并行处理

一些处理技巧:
- 外部排序: 多路归并, 桶排序
- 哈希分片
- 位图

常见的问题:
- 海量数据的排序
- 海量数据的查询
- 海量数据的TOPK
- 海量数据求频率TOP K
- 海量数据 去重/找重
- 两个(多个)海量数据文件找重

#### 解决此类问题的方法,假设在内存足够的情况下进行治理计算,找到合适的数据结果及方法解决问题后,在内存不充足的情况下分治解决问题

### 问题一: 按照金额大小给10GB的订单文件进行排序?
> 加入当前外存(硬盘)存储了这 10GB 数据, 内存大小为 1.2GB, 每次从外存中读取 1G 左右的数据, 加入内存进行排序, 将排序结果放置在外存的小
> 文件中, 命名为 n.txt
> 经过 10 次左右就可以将这 10G 的数据分别排序到 10 个 1G 左右的 .txt 文件中
> 内存中加载一个 len 为 10 的数组, 没了减少 io, 从10个 .txt 文件各自抽取 100M 左右的数据, 逐次读取 100M 中的一个数据
> 经过比较将每次的 len 为 10 的数组 中最小的数据, 写入到合并的最终文件中即可

### 问题二: 有一个IP地址白(黑)名单文件，包含10亿个IP地址，判断某IP是否在白(黑)名单中？
> ip 普遍认为是 32bit 4字节, 10亿情况下也就是 10^9 * 4 = 4GB, 在内存足够的情况下, 构造成哈希表,红黑树进行快速的查找
> 假设目前每台及其的实际内存为 2.5GB, 我们采用 hash 分片的方式, MD5(ip)%4 = 0~3, 加入是多机器的情况下, 每台机器上
> 放置 2.5GB 数据, 查询的时候 MD5(ip)%4 到对应机器上查询数据即可, 每天机器上的数据为了快速查找构建成 hash 表 或者 红黑树 加速查找

### 问题三: 10亿个整数，判断某个整数是否在其中？
> 整体思路与题目二处理方式一致

### 问题四: 10亿个整数，放在文件中，内存有限，如何求最大的TOP100个整数？
> 这里出现了 TOP值, 就可以联想到使用 堆 来解决问题, 构建堆模型, 内存每次从源数据中预读 500M 数据, 加入内存, 减少 IO,
> 内存依次从 500M 数据中读取并构建堆模型(小顶堆)

### 问题五: 100GB的搜索关键字文件，统计出现频率TOP100关键词？
问题可以大致分为两部完成
- 统计每个单词出现的频率
- - 使用排序
- - 使用 hash 表
- 小顶堆进行排序

统计频率如果使用排序的方式, 那么就转化成了 问题一, 然后使用 小顶堆 取TOP值即可

如果使用 hash 表, 那就就采用 hash 分片的方式解决问题, 然后使用 小顶堆 取TOP值即可
### 问题六: 一个文件中包含 10亿 条URL，有可能会重复，将重复的去掉？
> 一个 URL 大约 64字节, 128 bit, 约为 64G

问题是去重,那么去重可以有一下几种方式:
- 排序 (取一个临时变量记录上一个 URL(用于排序方法))
- hash 表

> 加入我们的内存为 9GB, 每次读取 8GB 的数据, 按照排序的方式进行(问题一)
> 如果按照 hash 分片方式, 就可以不使用临时的 URL 记录变量(相同的url一定会被分配到同一个桶中)
### 问题七: 给你 a、b 两个文件，各自有 50亿 条URL，每条URL占用 64字节，内存限制是 4GB，找出 a、b 文件共同的URL？
方式有两种:
- 各自排序, 双指针遍历
- 使用 hash 表, 一个记录, 一个查询